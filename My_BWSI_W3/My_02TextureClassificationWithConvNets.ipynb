{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"My_02TextureClassificationWithConvNets.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"a7scg4EGMfYk","colab_type":"text"},"cell_type":"markdown","source":["# Tissue Classification using Neural Networks\n","In this lab we will explore the use of texture in images and traditional machine learning approaches such as clustering. The dataset we will be using is available here: http://dx.doi.org/10.5281/zenodo.53169. \n","\n","![alt text](https://www.researchgate.net/profile/Jakob_Kather/publication/303998214/figure/fig7/AS:391073710002224@1470250646407/Representative-images-from-our-dataset-Here-the-first-10-images-of-every-tissue-class.png)\n","\n","The above figure shows the 8 different classes of tissue we will be trying to identify. "]},{"metadata":{"id":"W86Oi6dCMfYp","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Imports\n","from __future__ import print_function\n","import os\n","import numpy as np\n","import matplotlib.pylab as plt\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.layers import MaxPool2D\n","from tensorflow.keras.optimizers import SGD\n","from tensorflow.keras.utils import to_categorical"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DfDmvdh7MfYx","colab_type":"text"},"cell_type":"markdown","source":["## Step 1\n","* Load the data (done for you)\n"," * The \"data\" variable stores 5000 images of shape 150x150. This means data has shape (5000, 150, 150). These images are loaded here as grayscale.\n"," * The \"labels\" variable stores 5000 labels (0-7). This means \"labels\" has shape (5000,)\n","* Split data into training and testing subsets (left up to you)\n"," * Check out the sklearn function train_test_split from sklearn.model_selection"]},{"metadata":{"id":"vTPG58OXMfYz","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"149a5935-9b69-4134-f1e7-b82e31b29617","executionInfo":{"status":"ok","timestamp":1532460629640,"user_tz":240,"elapsed":1742,"user":{"displayName":"Caroline J","photoUrl":"//lh5.googleusercontent.com/-UW6T_Czu5Tc/AAAAAAAAAAI/AAAAAAAAAmk/_PdmajiiHBY/s50-c-k-no/photo.jpg","userId":"115113466279912359883"}}},"cell_type":"code","source":["! git clone https://github.com/BeaverWorksMedlytics/Week3_public.git\n","\n","# Build the path to the data folder. No need to change directories\n","# There are a total of 6 files you will have to load\n","data_dir = os.path.join( os.getcwd(), 'Week3_public', 'data', 'crc')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["fatal: destination path 'Week3_public' already exists and is not an empty directory.\r\n"],"name":"stdout"}]},{"metadata":{"id":"mF4iIwc8MfY4","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":207},"outputId":"0c380614-0708-4d9b-9bec-6444f472d9b4","executionInfo":{"status":"ok","timestamp":1532462031837,"user_tz":240,"elapsed":1515,"user":{"displayName":"Caroline J","photoUrl":"//lh5.googleusercontent.com/-UW6T_Czu5Tc/AAAAAAAAAAI/AAAAAAAAAmk/_PdmajiiHBY/s50-c-k-no/photo.jpg","userId":"115113466279912359883"}}},"cell_type":"code","source":["# Load data and split into training, testing sets\n","y = np.load(os.path.join(data_dir, 'rgb01.npz'))\n","labels = y['labels']\n","data = y['rgb_data']\n","data = data[:,:,:,0]\n","label_str = y['label_str']\n","label_str = label_str.tolist() # this is to convert label_str back to a dictionary\n","y = []\n","\n","print(data.shape)\n","for ii in range(2,6):\n","    filename = os.path.join(data_dir, 'rgb0' + str(ii) + '.npz')\n","    print('loading ', filename)\n","    y = np.load(filename)\n","    labels = np.append(labels, y['labels'], axis=0)\n","    data = np.append(data, y['rgb_data'][:,:,:,0], axis=0)\n","    print(data.shape)\n","    y = []\n","\n","\n","print( data.shape )\n","print( labels.shape )"],"execution_count":34,"outputs":[{"output_type":"stream","text":["(1000, 150, 150)\n","loading  /content/Week3_public/data/crc/rgb02.npz\n","(2000, 150, 150)\n","loading  /content/Week3_public/data/crc/rgb03.npz\n","(3000, 150, 150)\n","loading  /content/Week3_public/data/crc/rgb04.npz\n","(4000, 150, 150)\n","loading  /content/Week3_public/data/crc/rgb05.npz\n","(5000, 150, 150)\n","(5000, 150, 150)\n","(5000,)\n"],"name":"stdout"}]},{"metadata":{"id":"KXc9uKk7oYDP","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":207},"outputId":"b0f61966-e4c0-46d3-e2d4-ebface0d8e35","executionInfo":{"status":"ok","timestamp":1532460643820,"user_tz":240,"elapsed":2017,"user":{"displayName":"Caroline J","photoUrl":"//lh5.googleusercontent.com/-UW6T_Czu5Tc/AAAAAAAAAAI/AAAAAAAAAmk/_PdmajiiHBY/s50-c-k-no/photo.jpg","userId":"115113466279912359883"}}},"cell_type":"code","source":["###### ATTEMPT 2 #######\n","# Load data and split into training, testing sets\n","y = np.load(os.path.join(data_dir, 'rgb01.npz'))\n","labels = y['labels']\n","data = y['rgb_data']\n","data = data[:,:,:,0:3] #takes only the r value\n","label_str = y['label_str']\n","label_str = label_str.tolist() # this is to convert label_str back to a dictionary\n","y = []\n","\n","print(data.shape)\n","for ii in range(2,6):\n","    filename = os.path.join(data_dir, 'rgb0' + str(ii) + '.npz')\n","    print('loading ', filename)\n","    y = np.load(filename)\n","    labels = np.append(labels, y['labels'], axis=0)\n","    data = np.append(data, y['rgb_data'][:,:,:,0:3], axis=0)\n","    print(data.shape)\n","    y = []\n","\n","\n","print( data.shape )\n","print( labels.shape )"],"execution_count":4,"outputs":[{"output_type":"stream","text":["(1000, 150, 150, 3)\n","loading  /content/Week3_public/data/crc/rgb02.npz\n","(2000, 150, 150, 3)\n","loading  /content/Week3_public/data/crc/rgb03.npz\n","(3000, 150, 150, 3)\n","loading  /content/Week3_public/data/crc/rgb04.npz\n","(4000, 150, 150, 3)\n","loading  /content/Week3_public/data/crc/rgb05.npz\n","(5000, 150, 150, 3)\n","(5000, 150, 150, 3)\n","(5000,)\n"],"name":"stdout"}]},{"metadata":{"id":"EnTT4tyXMfY9","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":207},"outputId":"131f9839-b48e-4f82-a15a-f4961f17a303","executionInfo":{"status":"ok","timestamp":1532462038626,"user_tz":240,"elapsed":676,"user":{"displayName":"Caroline J","photoUrl":"//lh5.googleusercontent.com/-UW6T_Czu5Tc/AAAAAAAAAAI/AAAAAAAAAmk/_PdmajiiHBY/s50-c-k-no/photo.jpg","userId":"115113466279912359883"}}},"cell_type":"code","source":["##### ATTEMPT 1 #############\n","num_images, nrows, ncols = data.shape\n","\n","# split into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size = 0.25)\n","print(\"Current separation:\", X_train.shape, y_train.shape)\n","\n","# convert the labels from 1-D arrays to categorical type \n","print(\"Previous Label:\", y_train[0])\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)\n","print(\"New Label Shape:\", y_train.shape)\n","\n","#make train and validation\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.25)\n","\n","print(\"New Label Shape:\", y_train.shape)\n","print('Validation Sample:', y_val)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Current separation: (3750, 150, 150) (3750,)\n","Previous Label: 3\n","New Label Shape: (3750, 8)\n","New Label Shape: (2812, 8)\n","Validation Sample: [[0. 0. 0. ... 0. 1. 0.]\n"," [0. 0. 0. ... 0. 1. 0.]\n"," [0. 1. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 1. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 1.]]\n"],"name":"stdout"}]},{"metadata":{"id":"mIMtJKPZphTV","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":587},"outputId":"12a84b26-be0d-4627-f8ba-033d03ec36c5","executionInfo":{"status":"ok","timestamp":1532460697525,"user_tz":240,"elapsed":45350,"user":{"displayName":"Caroline J","photoUrl":"//lh5.googleusercontent.com/-UW6T_Czu5Tc/AAAAAAAAAAI/AAAAAAAAAmk/_PdmajiiHBY/s50-c-k-no/photo.jpg","userId":"115113466279912359883"}}},"cell_type":"code","source":["##### ATTEMPT 2 ############\n","\n","num_images, nrows, ncols, nrgb = data.shape\n","\n","### COLOR SPACE ATTEMPT ####\n","from skimage.color import rgb2lab\n","\n","num_images, nrows, ncols, nrgb = data.shape\n","\n","num_steps = 2\n","\n","new_data = np.zeros(shape = (num_images//num_steps, nrows, ncols, nrgb))\n","for i in range(0, num_images, num_steps):\n","  new_data[i//2] = rgb2lab(data[i])\n","  if (i % 250 == 0):\n","    print(i, new_data.shape)\n","\n","data = new_data.reshape((num_images//num_steps, nrows*ncols*nrgb))\n","labels = labels[0:num_images:num_steps]\n","print(data.shape)\n","\n","# split into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size = 0.25)\n","print(\"Current separation:\", X_train.shape, y_train.shape)\n","\n","# convert the labels from 1-D arrays to categorical type \n","print(\"Previous Label:\", y_train[0])\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)\n","print(\"New Label Shape:\", y_train.shape)\n","\n","#make train and validation\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.25)\n","\n","print(\"New Label Shape:\", X_train[0])\n","print('Validation Sample:', y_val)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["0 (2500, 150, 150, 3)\n","250 (2500, 150, 150, 3)\n","500 (2500, 150, 150, 3)\n","750 (2500, 150, 150, 3)\n","1000 (2500, 150, 150, 3)\n","1250 (2500, 150, 150, 3)\n","1500 (2500, 150, 150, 3)\n","1750 (2500, 150, 150, 3)\n","2000 (2500, 150, 150, 3)\n","2250 (2500, 150, 150, 3)\n","2500 (2500, 150, 150, 3)\n","2750 (2500, 150, 150, 3)\n","3000 (2500, 150, 150, 3)\n","3250 (2500, 150, 150, 3)\n","3500 (2500, 150, 150, 3)\n","3750 (2500, 150, 150, 3)\n","4000 (2500, 150, 150, 3)\n","4250 (2500, 150, 150, 3)\n","4500 (2500, 150, 150, 3)\n","4750 (2500, 150, 150, 3)\n","(2500, 67500)\n","Current separation: (1875, 67500) (1875,)\n","Previous Label: 2\n","New Label Shape: (1875, 8)\n","New Label Shape: [ 75.56914658   7.94578876  -8.55033295 ...  77.05643067  13.55628455\n"," -14.93794215]\n","Validation Sample: [[0. 0. 0. ... 1. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 1. 0.]\n"," ...\n"," [0. 1. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 1.]]\n"],"name":"stdout"}]},{"metadata":{"id":"_gkEPcSMu4bL","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"651c3126-1495-4f46-e165-24a61a3cae12","executionInfo":{"status":"ok","timestamp":1532460702860,"user_tz":240,"elapsed":680,"user":{"displayName":"Caroline J","photoUrl":"//lh5.googleusercontent.com/-UW6T_Czu5Tc/AAAAAAAAAAI/AAAAAAAAAmk/_PdmajiiHBY/s50-c-k-no/photo.jpg","userId":"115113466279912359883"}}},"cell_type":"code","source":["print(X_train.shape, X_val.shape)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["(1406, 67500) (469, 67500)\n"],"name":"stdout"}]},{"metadata":{"id":"PtlCeN4FMfZD","colab_type":"text"},"cell_type":"markdown","source":["## Normalize data\n","All images should be normalized to the range 0-1 by dividing by 255.\n","\n","#### Note\n","* Using the La\\*b colorspace : If you convert your images to the La\\*b colorspace, the scaling factor will change. Each channel in this colorspace will have a different range and normalization of each space will involve scaling each channel separately. Additionally, the a\\* channel can have a negative range. This also needs to be taken into account. \n","* Using the HSV/HSI colorspace : Similar considerations apply if you are using the HSV/HSI colorspace. The only difference is that the HSV/HSI colorspace will have all positive values."]},{"metadata":{"id":"_FeL1EP5MfZF","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":155},"outputId":"0af7bf22-18f8-4550-ab2b-98428eda6ddb","executionInfo":{"status":"ok","timestamp":1532462051529,"user_tz":240,"elapsed":1616,"user":{"displayName":"Caroline J","photoUrl":"//lh5.googleusercontent.com/-UW6T_Czu5Tc/AAAAAAAAAAI/AAAAAAAAAmk/_PdmajiiHBY/s50-c-k-no/photo.jpg","userId":"115113466279912359883"}}},"cell_type":"code","source":["##### ATTEMPT 1 ########\n","### just divide by 255 #####\n","\n","n_images, n_rows, n_cols = X_train.shape\n","X_train = X_train.astype('float')\n","\n","X_train = X_train/255\n","\n","print('After reshape:', X_train.shape)\n","\n","#normalize the test data\n","n_images, n_rows, n_cols = X_test.shape\n","\n","X_test = X_test.astype('float')\n","X_test = X_test/255\n","\n","X_val = X_val.astype('float')\n","X_val = X_val/255\n","\n","print('Current y_test', y_test)"],"execution_count":36,"outputs":[{"output_type":"stream","text":["After reshape: (2812, 150, 150)\n","Current y_test [[0. 0. 1. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 1. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]]\n"],"name":"stdout"}]},{"metadata":{"id":"rwhnYeQNju4N","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"dfe4151b-58d7-4721-868a-8a48a749814e","executionInfo":{"status":"ok","timestamp":1532462009328,"user_tz":240,"elapsed":670,"user":{"displayName":"Caroline J","photoUrl":"//lh5.googleusercontent.com/-UW6T_Czu5Tc/AAAAAAAAAAI/AAAAAAAAAmk/_PdmajiiHBY/s50-c-k-no/photo.jpg","userId":"115113466279912359883"}}},"cell_type":"code","source":["##### ATTEMPT 2 #####\n","### COLOR SPACE ATTEMPT ####\n","print(max(X_train[100]))"],"execution_count":33,"outputs":[{"output_type":"stream","text":["94.39523554522545\n"],"name":"stdout"}]},{"metadata":{"id":"QAgbBOzBMfZI","colab_type":"text"},"cell_type":"markdown","source":["## Step 2\n","At this point, the data has been split into training and testing sets and normalized. We will now design a fully connected neural network for texture classification. \n","\n","\n","![alt text](http://adventuresinmachinelearning.com/wp-content/uploads/2017/04/CNN-example-block-diagram.jpg)\n","\n","\n","( Image from http://adventuresinmachinelearning.com/keras-tutorial-cnn-11-lines/ )\n","\n","When designing a fully connected network for classification, we have several decisions to make.\n","\n","**Network Architecuture**\n","* How many layers will our network have ?\n","* How many convolutional filters per layer ?\n","    * What is an appropriate filter size ? \n","* What is an appropriate batch size, learning rate and number of training epochs ?\n","\n","**Data input**\n","* Do we use the raw data ?\n","    * RGB or just gray channel ?\n","* Does the use of different colorspaces lead to better results for a given network architecture ?\n","* Can we use any of the texture features from the previous lab as inputs to this model ?\n","* How does data augmentation affect the results ? \n","\n","Other considerations, we will not be exploring :\n","* What is the trade-off between input data sizes and batch size ?\n","* Is the GPU always the appropriate platform for training ?\n","* How does hardware influence inputs and batch sizes for a given desired accuracy ?"]},{"metadata":{"id":"82ImTGQ_MfZJ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Define the data shapes based on your decision to use rgb or grayscale or other colorpsaces or texture features or \n","# some combination of these inputs\n","num_classes = 8 \n","input_shape = nrows, ncols, 1\n","train_data = X_train.reshape(X_train.shape[0], nrows, ncols, 1)\n","test_data = X_test.reshape(X_test.shape[0], nrows, ncols, 1)\n","val_data = X_val.reshape(X_val.shape[0], nrows, ncols, 1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OTs1Ekcpv3JV","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["##### ATTEMPT 2 #######\n","# Define the data shapes based on your decision to use rgb or grayscale or other colorpsaces or texture features or \n","# some combination of these inputs\n","num_classes = 8 \n","input_shape = nrows, ncols, 3\n","train_data = X_train.reshape(X_train.shape[0], nrows, ncols, 3)\n","test_data = X_test.reshape(X_test.shape[0], nrows, ncols, 3)\n","val_data = X_val.reshape(X_val.shape[0], nrows, ncols, 3)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Q2iSGtOuMfZP","colab_type":"text"},"cell_type":"markdown","source":["## Step 3\n","Design your network here using Keras"]},{"metadata":{"id":"346Iv5RjvBTz","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":345},"outputId":"89a9eed1-216a-40a6-9827-932f7ff44427","executionInfo":{"status":"ok","timestamp":1532462068603,"user_tz":240,"elapsed":678,"user":{"displayName":"Caroline J","photoUrl":"//lh5.googleusercontent.com/-UW6T_Czu5Tc/AAAAAAAAAAI/AAAAAAAAAmk/_PdmajiiHBY/s50-c-k-no/photo.jpg","userId":"115113466279912359883"}}},"cell_type":"code","source":["#### Model 2 ######\n","from tensorflow.keras.layers import GlobalMaxPool2D, Dropout\n","model = []\n","model = Sequential()\n","\n","# Add input layer\n","\n","# Add fully connected layers \n","# See keras.io for Conv2D, MaxPool2D, Dropout documentation\n","model.add(Conv2D(32, kernel_size=(5,5), strides=1, padding=\"same\",  activation = 'relu', input_shape=input_shape))\n","model.add(MaxPool2D(pool_size=(3, 3), strides=(3, 3)))\n","model.add(Conv2D(32, kernel_size=(5,5), strides=1, padding=\"same\",  activation = 'relu', input_shape=input_shape))\n","model.add(MaxPool2D(pool_size=(3, 3), strides=(3, 3)))\n","model.add(Flatten())\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.summary()"],"execution_count":38,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_21 (Conv2D)           (None, 150, 150, 32)      832       \n","_________________________________________________________________\n","max_pooling2d_20 (MaxPooling (None, 50, 50, 32)        0         \n","_________________________________________________________________\n","conv2d_22 (Conv2D)           (None, 50, 50, 32)        25632     \n","_________________________________________________________________\n","max_pooling2d_21 (MaxPooling (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","flatten_10 (Flatten)         (None, 8192)              0         \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 8)                 65544     \n","=================================================================\n","Total params: 92,008\n","Trainable params: 92,008\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"OsffMC7mMfZQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":380},"outputId":"210ab0a3-10ff-4ebe-f0f5-daae2a87d2e3","executionInfo":{"status":"ok","timestamp":1532459223769,"user_tz":240,"elapsed":961,"user":{"displayName":"Caroline J","photoUrl":"//lh5.googleusercontent.com/-UW6T_Czu5Tc/AAAAAAAAAAI/AAAAAAAAAmk/_PdmajiiHBY/s50-c-k-no/photo.jpg","userId":"115113466279912359883"}}},"cell_type":"code","source":["# Create your network\n","model = []\n","model = Sequential()\n","\n","# Add input layer\n","\n","# Add fully connected layers \n","# See keras.io for Conv2D, MaxPool2D, Dropout documentation\n","model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n","                 activation='relu',\n","                 input_shape=input_shape))\n","model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n","model.add(Conv2D(64, (5, 5), activation='relu'))\n","model.add(MaxPool2D(pool_size=(2, 2)))\n","model.add(Flatten())\n","model.add(Dense(1000, activation='relu'))\n","\n","\n","# Add final output layer - This should have as many neurons as the number\n","# of classes we are trying to identify\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.summary()\n"],"execution_count":50,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_11 (Conv2D)           (None, 146, 146, 32)      832       \n","_________________________________________________________________\n","max_pooling2d_9 (MaxPooling2 (None, 73, 73, 32)        0         \n","_________________________________________________________________\n","conv2d_12 (Conv2D)           (None, 69, 69, 64)        51264     \n","_________________________________________________________________\n","max_pooling2d_10 (MaxPooling (None, 34, 34, 64)        0         \n","_________________________________________________________________\n","flatten_4 (Flatten)          (None, 73984)             0         \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 1000)              73985000  \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 8)                 8008      \n","=================================================================\n","Total params: 74,045,104\n","Trainable params: 74,045,104\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"3DwOWHAVMfZU","colab_type":"text"},"cell_type":"markdown","source":["## Step 4\n","Compile the model you designed. Compiltation of the Keras model results in the initialization of model weights and sets other model properties."]},{"metadata":{"id":"azIn2h-PMfZV","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from tensorflow.train import AdamOptimizer\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=AdamOptimizer(0.001),\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9afYIYb6MfZZ","colab_type":"text"},"cell_type":"markdown","source":["## Step 5\n","Train model"]},{"metadata":{"id":"_gCBg0Cbgj4g","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"579a37ff-09b0-4623-8eec-6c025743fb2f","executionInfo":{"status":"ok","timestamp":1532462085574,"user_tz":240,"elapsed":664,"user":{"displayName":"Caroline J","photoUrl":"//lh5.googleusercontent.com/-UW6T_Czu5Tc/AAAAAAAAAAI/AAAAAAAAAmk/_PdmajiiHBY/s50-c-k-no/photo.jpg","userId":"115113466279912359883"}}},"cell_type":"code","source":["###make a smaller dataset\n","\n","print(train_data.shape, y_train.shape)"],"execution_count":40,"outputs":[{"output_type":"stream","text":["(2812, 150, 150, 1) (2812, 8)\n"],"name":"stdout"}]},{"metadata":{"id":"_ngFO-dYMfZa","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":1102},"outputId":"88ea7af7-cf43-4a6e-86ac-28882c08e74d","executionInfo":{"status":"error","timestamp":1532463355358,"user_tz":240,"elapsed":1264091,"user":{"displayName":"Caroline J","photoUrl":"//lh5.googleusercontent.com/-UW6T_Czu5Tc/AAAAAAAAAAI/AAAAAAAAAmk/_PdmajiiHBY/s50-c-k-no/photo.jpg","userId":"115113466279912359883"}}},"cell_type":"code","source":["batch_size = 20\n","epochs = 100\n","history = model.fit(train_data, y_train,\n","              batch_size=batch_size,\n","              epochs=epochs,\n","              validation_data=(val_data, y_val),\n","              verbose=1)"],"execution_count":41,"outputs":[{"output_type":"stream","text":["Train on 2812 samples, validate on 938 samples\n","Epoch 1/100\n","2812/2812 [==============================] - 122s 43ms/step - loss: 1.3598 - acc: 0.4250 - val_loss: 1.0319 - val_acc: 0.5267\n","Epoch 2/100\n","2812/2812 [==============================] - 122s 43ms/step - loss: 0.9097 - acc: 0.6195 - val_loss: 0.8385 - val_acc: 0.6674\n","Epoch 3/100\n","1900/2812 [===================>..........] - ETA: 35s - loss: 0.8557 - acc: 0.6516"],"name":"stdout"},{"output_type":"stream","text":["2812/2812 [==============================] - 122s 43ms/step - loss: 0.8269 - acc: 0.6696 - val_loss: 0.7832 - val_acc: 0.6674\n","Epoch 4/100\n","2812/2812 [==============================] - 122s 44ms/step - loss: 0.7319 - acc: 0.7169 - val_loss: 1.0730 - val_acc: 0.5736\n","Epoch 5/100\n","2812/2812 [==============================] - 122s 43ms/step - loss: 0.6879 - acc: 0.7301 - val_loss: 0.7675 - val_acc: 0.6823\n","Epoch 6/100\n"," 540/2812 [====>.........................] - ETA: 1:28 - loss: 0.6816 - acc: 0.7074"],"name":"stdout"},{"output_type":"stream","text":["2812/2812 [==============================] - 122s 44ms/step - loss: 0.6826 - acc: 0.7312 - val_loss: 0.8761 - val_acc: 0.6471\n","Epoch 7/100\n","2812/2812 [==============================] - 122s 43ms/step - loss: 0.5966 - acc: 0.7752 - val_loss: 0.7807 - val_acc: 0.6759\n","Epoch 8/100\n","2812/2812 [==============================] - 122s 43ms/step - loss: 0.5632 - acc: 0.7959 - val_loss: 0.7469 - val_acc: 0.7143\n","Epoch 9/100\n"," 320/2812 [==>...........................] - ETA: 1:37 - loss: 0.5771 - acc: 0.7750"],"name":"stdout"},{"output_type":"stream","text":["2812/2812 [==============================] - 122s 44ms/step - loss: 0.5100 - acc: 0.8126 - val_loss: 0.8279 - val_acc: 0.6962\n","Epoch 10/100\n","2812/2812 [==============================] - 124s 44ms/step - loss: 0.4621 - acc: 0.8329 - val_loss: 0.8444 - val_acc: 0.6898\n","Epoch 11/100\n"," 960/2812 [=========>....................] - ETA: 1:12 - loss: 0.3891 - acc: 0.8542"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-8fe5ed493b01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m               verbose=1)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    251\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2895\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m     \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"sjAqutu2MfZf","colab_type":"text"},"cell_type":"markdown","source":["## Step 6\n","See how your model performs by uisng it for inference.\n","* What is the accuracy of classification ?\n","* Change your model, re-compile and test. Can you improve the accuracy of the model ?\n"]},{"metadata":{"id":"5M0N76AoMfZf","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# predict labels - use the test set for prediction\n","pred_labels = model.predict(test_data)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Xnuyx0QFMfZk","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":173},"outputId":"2bc93f31-9ac2-45fc-f4c6-698d9a08d60f","executionInfo":{"status":"ok","timestamp":1532463388938,"user_tz":240,"elapsed":612,"user":{"displayName":"Caroline J","photoUrl":"//lh5.googleusercontent.com/-UW6T_Czu5Tc/AAAAAAAAAAI/AAAAAAAAAmk/_PdmajiiHBY/s50-c-k-no/photo.jpg","userId":"115113466279912359883"}}},"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix\n","\n","# We need to convert the categorical array test_labels into a vector\n","# in order to use it in the calculation of the confusion matrix\n","mat = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(pred_labels, axis = 1))\n","acc = accuracy_score(np.argmax(y_test, axis=1), np.argmax(pred_labels, axis = 1))\n","print(acc)\n","print(mat)"],"execution_count":43,"outputs":[{"output_type":"stream","text":["0.6928\n","[[ 72   1  64   0  18   0   0   0]\n"," [  7  49   4  14  65   0  20   0]\n"," [ 37   0  96   0   9   0   0   2]\n"," [  0   5   2 116  15   0  16   0]\n"," [ 26   6  11   0 110   0   7   0]\n"," [  0   0   0   0   0 168   0   1]\n"," [  2   0   0   0  11   0 141   0]\n"," [  2   0   6   0   0  33   0 114]]\n"],"name":"stdout"}]},{"metadata":{"id":"h7RYbDzyMfZm","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":388},"outputId":"509b0efa-3cd1-44a2-a3b7-bd90bd7d9d58","executionInfo":{"status":"ok","timestamp":1532463391285,"user_tz":240,"elapsed":625,"user":{"displayName":"Caroline J","photoUrl":"//lh5.googleusercontent.com/-UW6T_Czu5Tc/AAAAAAAAAAI/AAAAAAAAAmk/_PdmajiiHBY/s50-c-k-no/photo.jpg","userId":"115113466279912359883"}}},"cell_type":"code","source":["plt.figure(figsize=(8,6))\n","plt.imshow(mat, cmap='hot', interpolation='nearest')\n","plt.grid(False)\n","plt.colorbar()\n","plt.xlabel('true label')\n","plt.ylabel('predicted label')\n","plt.show()"],"execution_count":44,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAa0AAAFzCAYAAACNYlZoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbIPQAgDYxv8CwCpoiJRg8EEAAAAASUVORK5CYII=\n","text/plain":["<matplotlib.figure.Figure at 0x7fd9197f7b70>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"p6atMD6vMfZs","colab_type":"text"},"cell_type":"markdown","source":["## Assignment\n","* In Step 3 design your own network\n","* Does the model perform better if you use all three RGB channels ?\n","* How does the performance change when using the La*b colorspace ?\n"]},{"metadata":{"id":"HQ6qvyk4qntM","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["\n","# Load data as RGB\n","y = np.load(os.path.join(data_dir, 'rgb01.npz'))\n","labels = y['labels']\n","data_rgb = y['rgb_data']\n","label_str = y['label_str']\n","label_str = label_str.tolist() # this is to convert label_str back to a dictionary\n","y = []\n","\n","print(data_rgb.shape)\n","for ii in range(2,6):\n","    filename = os.path.join(data_dir, 'rgb0' + str(ii) + '.npz')\n","    print('loading ', filename)\n","    y = np.load(filename)\n","    labels = np.append(labels, y['labels'], axis=0)\n","    data_rgb = np.append(data_rgb, y['rgb_data'])\n","    print(data_rgb.shape)\n","    y = []\n","\n","data_rgb = data_rgb.astype('float')\n","data_rgb = data_rgb.reshape(5000, 150, 150, 3)\n","\n","print( data_rgb.shape )\n","print( labels.shape )\n","\n","num_images, nrows, ncols, dims = data_rgb.shape"],"execution_count":0,"outputs":[]}]}