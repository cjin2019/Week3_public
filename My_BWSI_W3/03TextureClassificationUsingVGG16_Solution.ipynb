{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03TextureClassificationUsingVGG16_Solution.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"9gPF149V-3xl","colab_type":"text"},"cell_type":"markdown","source":["## Using pre-trained models for Texture Classification\n","In this lab, we will use pre-trained models for the same texture classification task. The dataset we will be using is available here: http://dx.doi.org/10.5281/zenodo.53169. \n","\n","![alt text](https://www.researchgate.net/profile/Jakob_Kather/publication/303998214/figure/fig7/AS:391073710002224@1470250646407/Representative-images-from-our-dataset-Here-the-first-10-images-of-every-tissue-class.png)\n","\n","The above figure shows the 8 different classes of tissue we will be trying to identify. "]},{"metadata":{"id":"2XS4HHKf-3xo","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from __future__ import print_function\n","import os\n","import numpy as np\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras import Model, Sequential\n","from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n","from tensorflow.keras.applications import VGG16\n","from matplotlib import pylab as plt\n","from skimage.color import rgb2lab, rgb2hsv"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1W3NwJ48-3xz","colab_type":"text"},"cell_type":"markdown","source":["## Step 1: Load pre-trained VGG16 model\n","We will use the VGG16 model as the feature extractor for this classification task. First, we need to download the pre-trained weights. The model has been trained on the ImageNet image classification dataset. For more details on this dataset see http://www.image-net.org/. "]},{"metadata":{"id":"6VCkl7rQ-3x1","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":72},"outputId":"3b8aa487-be7f-459d-e92c-d9dc3ec30fcd","executionInfo":{"status":"ok","timestamp":1532541226145,"user_tz":240,"elapsed":3385,"user":{"displayName":"Caroline J","photoUrl":"//lh5.googleusercontent.com/-UW6T_Czu5Tc/AAAAAAAAAAI/AAAAAAAAAmk/_PdmajiiHBY/s50-c-k-no/photo.jpg","userId":"115113466279912359883"}}},"cell_type":"code","source":["model = None\n","model = VGG16(weights='imagenet', include_top=False, input_shape = (150, 150, 3))\n","#model.summary()"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 1s 0us/step\n"],"name":"stdout"}]},{"metadata":{"id":"MtRugIuZ-3x9","colab_type":"text"},"cell_type":"markdown","source":["## VGG16\n","Let's examine the VGG16 model. The model has 16 layers as seen above. The model has the following specifications\n","* Expected input size : 224x224 pixels\n","* Number of output classes : 1000\n","\n","Our images are 150x150 pixels in size and come from only 10 categories. In order to use this model for our classification task, we need to do the following:\n","* Resize images : Our input images can be resized to the appropriate dimensions. Alternatively, we can pad our images to the expected dimensions. Padding leads to additional choices - Do we pad with zeros, duplicate edge pixels or mirror the image across edges ?\n","* Change the prediction layer : Remove the existing prediction layer and add a new layer that can predict 8 classes.\n","* Train : Finally, we need to train the network on our data"]},{"metadata":{"id":"5qee4CK6-3x_","colab_type":"text"},"cell_type":"markdown","source":["# Step 2\n","Load the data and resize images appropriately. Use the helper function in utils.py. The assumption is that you have already cloned the Week3 repo and know the path to the data folder."]},{"metadata":{"id":"_k5tmqKKEXnj","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def load_crc_data(data_dir):\n","    y = np.load(os.path.join(data_dir, 'rgb01.npz'))\n","    labels = y['labels']\n","    data = y['rgb_data']\n","    label_str = y['label_str']\n","    label_str = label_str.tolist() # this is to convert label_str back to a dictionary\n","    y = []\n","\n","    for ii in range(2,6):\n","        filename = os.path.join(data_dir, 'rgb0' + str(ii) + '.npz')\n","        print('loading ', filename)\n","        y = np.load(filename)\n","        labels = np.append(labels, y['labels'], axis=0)\n","        data = np.append(data, y['rgb_data'], axis=0)\n","        print(data.shape)\n","\n","    return data, labels, label_str"],"execution_count":0,"outputs":[]},{"metadata":{"id":"v4ISStKX-3yC","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":173},"outputId":"1543732e-c4c0-4edb-97d5-b6afd3cc7eae","executionInfo":{"status":"ok","timestamp":1532465285517,"user_tz":240,"elapsed":3931,"user":{"displayName":"Caroline J","photoUrl":"//lh5.googleusercontent.com/-UW6T_Czu5Tc/AAAAAAAAAAI/AAAAAAAAAmk/_PdmajiiHBY/s50-c-k-no/photo.jpg","userId":"115113466279912359883"}}},"cell_type":"code","source":["! git clone https://github.com/BeaverWorksMedlytics/Week3_public.git\n","#os.chdir('..')\n","from skimage.transform import resize\n","from sklearn.model_selection import train_test_split\n","data_dir = os.path.join( os.getcwd(), 'Week3_public', 'data', 'crc')\n","data, labels, label_str = load_crc_data(data_dir)\n","num_images = data.shape[0]"],"execution_count":26,"outputs":[{"output_type":"stream","text":["fatal: destination path 'Week3_public' already exists and is not an empty directory.\r\n","loading  /Week3_public/data/crc/rgb02.npz\n","(2000, 150, 150, 3)\n","loading  /Week3_public/data/crc/rgb03.npz\n","(3000, 150, 150, 3)\n","loading  /Week3_public/data/crc/rgb04.npz\n","(4000, 150, 150, 3)\n","loading  /Week3_public/data/crc/rgb05.npz\n","(5000, 150, 150, 3)\n"],"name":"stdout"}]},{"metadata":{"id":"R0ag5Lm5-3yJ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Resize data\n","#resized_data = np.zeros((num_images, 224, 224, 3))\n","#for ii in range(0, num_images):\n","#    resized_data[ii,::] = resize(data[ii,::], (224, 224, 3), mode='symmetric')\n","#data = resized_data\n","#resized_data = []\n","#print(data.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NEoblCFT-3yP","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#with open('resized.npz', 'wb') as fp:\n","#    np.savez(fp, data=data, labels=labels)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YptbEz_3-3yS","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Split data into train and test sets\n","train_images, test_images, train_labels, test_labels = train_test_split(data, labels, test_size=.2)\n","data = None\n","ntrain = train_images.shape[0]\n","ntest  = test_images.shape[0]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"36zJvME9B9R1","colab_type":"text"},"cell_type":"markdown","source":[""]},{"metadata":{"id":"zDQw9IrA-3yX","colab_type":"text"},"cell_type":"markdown","source":["## Step 3\n","We will now modify the pre-trained VGG network as described earlier. We will remove the following layers : \n","\n","<img src=\"images/final_layers.png\" width=\"65%\"></img> \n"]},{"metadata":{"id":"AA1U0Oe--3yY","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":656},"outputId":"e7c214c3-ed09-409f-ac83-5d8af995a16e","executionInfo":{"status":"ok","timestamp":1532465293387,"user_tz":240,"elapsed":852,"user":{"displayName":"Caroline J","photoUrl":"//lh5.googleusercontent.com/-UW6T_Czu5Tc/AAAAAAAAAAI/AAAAAAAAAmk/_PdmajiiHBY/s50-c-k-no/photo.jpg","userId":"115113466279912359883"}}},"cell_type":"code","source":["# remove the final layer in the model\n","for ii in range(0,4):\n","    model.layers.pop()\n","model.summary()"],"execution_count":29,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_3 (InputLayer)         (None, 150, 150, 3)       0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n","=================================================================\n","Total params: 7,635,264\n","Trainable params: 7,635,264\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"GgsfRGFN-3yc","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":1192},"outputId":"2c497063-8dea-4c3f-9208-5225263d7161","executionInfo":{"status":"ok","timestamp":1532465296561,"user_tz":240,"elapsed":683,"user":{"displayName":"Caroline J","photoUrl":"//lh5.googleusercontent.com/-UW6T_Czu5Tc/AAAAAAAAAAI/AAAAAAAAAmk/_PdmajiiHBY/s50-c-k-no/photo.jpg","userId":"115113466279912359883"}}},"cell_type":"code","source":["# Convert into sequential\n","seq_model = None\n","seq_model = Sequential()\n","for layer in model.layers:\n","    seq_model.add( layer )\n","seq_model.summary()\n","\n","for ii in range(0,1):\n","    seq_model.pop()\n","\n","seq_model.summary()"],"execution_count":30,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n","=================================================================\n","Total params: 7,635,264\n","Trainable params: 7,635,264\n","Non-trainable params: 0\n","_________________________________________________________________\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n","=================================================================\n","Total params: 7,635,264\n","Trainable params: 7,635,264\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"hkqoOtvN-3yi","colab_type":"text"},"cell_type":"markdown","source":["# Step 4\n","Freeze the layers that remain in our model."]},{"metadata":{"id":"QWiVwA-7-3yi","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":1227},"outputId":"bd177066-ed7e-4daa-d2b8-d32d2d753079","executionInfo":{"status":"ok","timestamp":1532465300910,"user_tz":240,"elapsed":929,"user":{"displayName":"Caroline J","photoUrl":"//lh5.googleusercontent.com/-UW6T_Czu5Tc/AAAAAAAAAAI/AAAAAAAAAmk/_PdmajiiHBY/s50-c-k-no/photo.jpg","userId":"115113466279912359883"}}},"cell_type":"code","source":["for layer in seq_model.layers:\n","    layer.trainable = False\n","seq_model.summary()\n","\n","seq_model.add( Flatten(name=\"my_flatten\") )\n","#seq_model.add( Dense(1024, activation=\"relu\", name=\"new_dense1\") )\n","#seq_model.add( Dropout(0.5) )\n","#seq_model.add( Dense(64, activation=\"relu\", name=\"new_dense2\") )\n","seq_model.add( Dense(8, activation=\"relu\", name=\"predictions\") )\n","\n","seq_model.summary()"],"execution_count":31,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n","=================================================================\n","Total params: 7,635,264\n","Trainable params: 0\n","Non-trainable params: 7,635,264\n","_________________________________________________________________\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n","_________________________________________________________________\n","my_flatten (Flatten)         (None, 165888)            0         \n","_________________________________________________________________\n","predictions (Dense)          (None, 8)                 1327112   \n","=================================================================\n","Total params: 8,962,376\n","Trainable params: 1,327,112\n","Non-trainable params: 7,635,264\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"uQDI5Thq-3yn","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["seq_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics = ['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TVRFOLnl-3yr","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["train_labels = to_categorical(train_labels)\n","test_labels = to_categorical(test_labels)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zONGCaxU-3yt","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["y = seq_model.fit(train_images, train_labels, validation_data=(test_images, test_labels),\n","                  batch_size=64, epochs=100, verbose=1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sL_rAFxKpGqi","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":235},"outputId":"21419097-702d-4c18-cf3e-b67ad1524ead","executionInfo":{"status":"error","timestamp":1532464894670,"user_tz":240,"elapsed":882,"user":{"displayName":"Caroline J","photoUrl":"//lh5.googleusercontent.com/-UW6T_Czu5Tc/AAAAAAAAAAI/AAAAAAAAAmk/_PdmajiiHBY/s50-c-k-no/photo.jpg","userId":"115113466279912359883"}}},"cell_type":"code","source":["print(y.history.keys())\n","# summarize history for accuracy\n","plt.plot(y.history['acc'])\n","plt.plot(y.history['val_acc'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()\n","# summarize history for loss\n","plt.plot(y.history['loss'])\n","plt.plot(y.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"],"execution_count":21,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-4873b4110fe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"]}]},{"metadata":{"id":"BMXtb6F_-3yx","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":235},"outputId":"04c85933-47e1-445d-9e73-5c37c765d0da","executionInfo":{"status":"error","timestamp":1532464905099,"user_tz":240,"elapsed":3827,"user":{"displayName":"Caroline J","photoUrl":"//lh5.googleusercontent.com/-UW6T_Czu5Tc/AAAAAAAAAAI/AAAAAAAAAmk/_PdmajiiHBY/s50-c-k-no/photo.jpg","userId":"115113466279912359883"}}},"cell_type":"code","source":["# convert images to LAB space and normalize\n","\n","lab_train = np.zeros((ntrain, 224, 224, 3))\n","ii = 0\n","for im in train_images:\n","    lab_train[ii,::] = rgb2lab(im)\n","    ii = ii + 1\n","    # normalize ?"],"execution_count":22,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-3f7d9b0ac05b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mii\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mlab_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrgb2lab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mii\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mii\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# normalize ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (150,150,3) into shape (224,224,3)"]}]},{"metadata":{"id":"hfUjXgKm-3y1","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["k = 1000\n","plt.figure(figsize=(40,20))\n","plt.subplot(2,4,1)\n","plt.imshow(train_images[k,::])\n","plt.axis('off')\n","for ii in range(0,3):\n","    plt.subplot(2,4,ii+2)\n","    plt.imshow(lab_train[k,:,:,ii])\n","    plt.gray()\n","    plt.axis('off')\n","im = train_images[k,::]\n","hsvim = rgb2hsv(im)\n","plt.subplot(2,4,6)\n","plt.imshow(hsvim[:,:,0])\n","plt.axis('off')\n","plt.subplot(2,4,7)\n","plt.imshow(hsvim[:,:,1])\n","plt.axis('off')\n","plt.subplot(2,4,8)\n","plt.imshow(hsvim[:,:,2])\n","plt.axis('off')\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sFJheF6w-3y7","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}